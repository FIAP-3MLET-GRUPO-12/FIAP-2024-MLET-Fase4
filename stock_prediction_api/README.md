# Stock Price Prediction API

A FastAPI-based REST API for serving LSTM model predictions for stock prices.

## ğŸ—ï¸ Architecture

```
api/
â”œâ”€â”€ models/              # Pydantic models for request/response
â”œâ”€â”€ services/           # Business logic and model handling
â”œâ”€â”€ middleware/         # Request logging and metrics
â”œâ”€â”€ routes/            # API endpoints
â””â”€â”€ main.py            # FastAPI application
```

## ğŸš€ Quick Start

### Local Development

1. Install dependencies:
```bash
pip install -r requirements.txt
```

2. Run the API:
```bash
uvicorn api.main:app --reload
```

### Docker

```bash
docker-compose up --build
```

## ğŸ” API Endpoints

### POST /predict

Make a prediction for the next day's closing price.

**Request:**
```json
{
    "sequence": [
        {
            "open": 150.0,
            "high": 155.0,
            "low": 149.0,
            "close": 153.0,
            "volume": 1000000.0
        }
    ]
}
```

**Response:**
```json
{
    "predicted_close": 155.50,
    "confidence_interval": {
        "lower": 153.25,
        "upper": 157.75
    }
}
```

### GET /health

Check API health status.

**Response:**
```json
{
    "status": "healthy",
    "timestamp": "2023-11-22T10:00:00.000Z"
}
```

### GET /metrics

Prometheus metrics endpoint.

## ğŸ“Š Monitoring

### Metrics Available

- `api_requests_total`: Total number of API requests
- `api_request_latency_seconds`: Request latency histogram
- `model_predictions_total`: Total predictions made

### Logging

- JSON formatted logs
- Request ID tracking
- Response time monitoring
- Error tracking

## ğŸ”’ Security

- Input validation with Pydantic
- CORS configuration
- Rate limiting (configurable)
- Non-root Docker user

## ğŸ§ª Testing

Run the test suite:
```bash
pytest tests/
```

## ğŸš¢ Configuration

Environment variables:
- `PORT`: API port (default: 8000)
- `ENVIRONMENT`: deployment environment
- `MODEL_PATH`: path to LSTM model
- `SCALER_PATH`: path to data scaler

## ğŸ“š Documentation

- API documentation: `http://localhost:8000/docs`
- OpenAPI spec: `http://localhost:8000/openapi.json`

## ğŸ”§ Development

1. Create a new branch
2. Make your changes
3. Add tests
4. Create a PR

For more details about deployment options and monitoring, see the main project [README.md](../README.md).

## Estrutura do Projeto

```
stock_prediction_api/
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ stock_data.py      # Modelos Pydantic para validaÃ§Ã£o
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â””â”€â”€ prediction.py      # ServiÃ§o de prediÃ§Ã£o
â”‚   â””â”€â”€ main.py               # AplicaÃ§Ã£o FastAPI
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ tesla_lstm_model.keras # Modelo LSTM salvo
â”‚   â””â”€â”€ scaler.joblib         # Scaler para normalizaÃ§Ã£o
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ integration/
â”‚   â”œâ”€â”€ unit/
â”‚   â””â”€â”€ test_api.py           # Testes da API
â””â”€â”€ requirements.txt          # DependÃªncias do projeto
```

## PrÃ©-requisitos

- Python 3.8+
- pip (gerenciador de pacotes Python)
- Modelo LSTM treinado
- Scaler ajustado aos dados

## InstalaÃ§Ã£o

1. Clone o repositÃ³rio:
```bash
git clone <repository-url>
cd stock_prediction_api
```

2. Instale as dependÃªncias:
```bash
pip install -r requirements.txt
```

## Salvando o Modelo

ApÃ³s treinar seu modelo LSTM, salve-o junto com o scaler:

```python
from api.services.prediction import save_artifacts

# ApÃ³s treinar seu modelo
save_artifacts(model, scaler)
```

## Exemplo de Uso

```python
import requests
import json

# Dados de exemplo (60 dias)
data = {
    "sequence": [
        {
            "open": 150.0,
            "high": 155.0,
            "low": 149.0,
            "close": 153.0,
            "volume": 1000000.0
        }
        # ... mais 59 dias
    ]
}

# Fazer previsÃ£o
response = requests.post("http://localhost:8000/predict", json=data)
prediction = response.json()
print(f"PrevisÃ£o de fechamento: ${prediction['predicted_close']:.2f}")
```

## Detalhes da ImplementaÃ§Ã£o

### 1. ValidaÃ§Ã£o de Dados
- Utiliza Pydantic para validaÃ§Ã£o de entrada
- Requer exatamente 60 dias de dados histÃ³ricos
- Valida tipos e formatos dos dados

### 2. Processamento de Dados
- NormalizaÃ§Ã£o automÃ¡tica usando o scaler salvo
- ConversÃ£o para formato numpy adequado ao modelo
- DesnormalizaÃ§Ã£o dos resultados

### 3. PrevisÃ£o
- Carrega modelo LSTM e scaler automaticamente
- Processa dados de entrada
- Calcula intervalo de confianÃ§a
- Retorna previsÃ£o desnormalizada

### 4. Tratamento de Erros
- ValidaÃ§Ã£o de entrada
- Erros de carregamento do modelo
- Erros durante a previsÃ£o
- Logging de erros

## Melhorias Futuras

1. **SeguranÃ§a**:
   - Adicionar autenticaÃ§Ã£o
   - Limitar requisiÃ§Ãµes por IP
   - Configurar CORS apropriadamente

2. **Performance**:
   - Implementar cache de modelo
   - Otimizar processamento de dados
   - Adicionar rate limiting

3. **Funcionalidades**:
   - Suporte a diferentes modelos
   - MÃ©tricas de confianÃ§a mais sofisticadas
   - Endpoints para mÃ©tricas e monitoramento

## Contribuindo

1. Fork o repositÃ³rio
2. Crie uma branch para sua feature
3. Commit suas mudanÃ§as
4. Push para a branch
5. Crie um Pull Request

 